{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "import numpy as np\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.preprocessing.data import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('./atec_anti_fraud_train.csv')\n",
    "df_test = pd.read_csv('./atec_anti_fraud_test_a.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0    977884\n",
      " 1     12122\n",
      "-1      4725\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# output label distribution.\n",
    "print(df_train.label.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## filter label == -1 and construct train set and validation set.\n",
    "new_df_train = df_train.loc[df_train.label != -1]\n",
    "X_all = new_df_train.loc[:, 'f1':'f290'].values\n",
    "y_all = new_df_train.loc[:, 'label'].values\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X_all, y_all, test_size = 0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shaple: (693004, 290), y_train shape: (693004,)\n",
      "X_valid shaple: (297002, 290), y_valid shape: (297002,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train shaple: %s, y_train shape: %s\" %(X_train.shape, y_train.shape))\n",
    "print(\"X_valid shaple: %s, y_valid shape: %s\" %(X_validation.shape, y_validation.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.5,\n",
       "       gamma=0, learning_rate=0.08, max_delta_step=0, max_depth=5,\n",
       "       min_child_weight=1, missing=None, n_estimators=50, nthread=24,\n",
       "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
       "       scale_pos_weight=81, seed=0, silent=True, subsample=0.9)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbdt = xgb.XGBClassifier(nthread=24, learning_rate=0.08, n_estimators=50,\n",
    "                         max_depth=5, gamma=0, subsample=0.9, colsample_bytree=0.5,\n",
    "                         scale_pos_weight=(y_train == 0).sum()/(y_train == 1).sum())\n",
    "gbdt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost validation auc: 0.98396\n"
     ]
    }
   ],
   "source": [
    "y_pred_validation = gbdt.predict_proba(X_validation)[:, 1]\n",
    "gbdt_validation_auc = roc_auc_score(y_validation, y_pred_validation)\n",
    "print('xgboost validation auc: %.5f' % gbdt_validation_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shaple: (693004, 1493), y_train shape: (693004,)\n",
      "X_valid shaple: (297002, 1493), y_valid shape: (297002,)\n"
     ]
    }
   ],
   "source": [
    "X_train_leaves = gbdt.apply(X_train)\n",
    "X_validation_leaves = gbdt.apply(X_validation)\n",
    "\n",
    "All_leaves = np.concatenate((X_train_leaves, X_validation_leaves), axis=0)\n",
    "All_leaves = All_leaves.astype(np.int32)\n",
    "\n",
    "xgbenc = OneHotEncoder()\n",
    "X_trans = xgbenc.fit_transform(All_leaves)\n",
    "\n",
    "(train_rows, cols) = X_train_leaves.shape\n",
    "X_train_trans = X_trans[:train_rows, :]\n",
    "X_train_valid = X_trans[train_rows:, :]\n",
    "print(\"X_train shaple: %s, y_train shape: %s\" %(X_train_trans.shape, y_train.shape))\n",
    "print(\"X_valid shaple: %s, y_valid shape: %s\" %(X_train_valid.shape, y_validation.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbdtenc_lr = LogisticRegression(class_weight='balanced')\n",
    "gbdtenc_lr.fit(X_trans[:train_rows, :], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbdt encoder lr validation auc: 0.98204\n"
     ]
    }
   ],
   "source": [
    "y_pred_val_gbdtenc_lr = gbdtenc_lr.predict_proba(X_trans[train_rows:, :])[:, 1]\n",
    "gbdtenc_lr_auc = roc_auc_score(y_validation, y_pred_val_gbdtenc_lr)\n",
    "print('gbdt encoder lr validation auc: %.5f' % gbdtenc_lr_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## use all dataset to train model and predict test set and output results.\n",
    "online_gbdt = xgb.XGBClassifier(nthread=24, learning_rate=0.08, n_estimators=50,\n",
    "                         max_depth=5, gamma=0, subsample=0.9, colsample_bytree=0.5,\n",
    "                         scale_pos_weight=(y_all == 0).sum()/(y_all == 1).sum())\n",
    "online_gbdt.fit(X_all, y_all)\n",
    "\n",
    "X_all_leaves = online_gbdt.apply(X_all)\n",
    "X_all_leaves = X_all_leaves.astype(np.int32)\n",
    "\n",
    "online_xgbenc = OneHotEncoder()\n",
    "X_all_trans = online_xgbenc.fit_transform(X_all_leaves)\n",
    "\n",
    "online_gbdtenc_lr = LogisticRegression(class_weight='balanced')\n",
    "online_gbdtenc_lr.fit(X_all_trans, y_all)\n",
    "\n",
    "X_test_leaves = online_gbdt.apply(df_test.loc[:, 'f1':'f290'].values)\n",
    "X_test_leaves = X_test_leaves.astype(np.int32)\n",
    "X_test_trans = online_xgbenc.transform(X_test_leaves)\n",
    "\n",
    "y_pred_test_gbdtenc_lr = online_gbdtenc_lr.predict_proba(X_test_trans)[:, 1]\n",
    "\n",
    "output_df = dp.DataFrame()\n",
    "output_df['id'] = df_test.id\n",
    "output_df['score'] = y_pred_test_gbdtenc_lr\n",
    "output_df.to_csv('output.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
